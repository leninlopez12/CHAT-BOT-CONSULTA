{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYA1gYZVecRl",
        "outputId": "dd39c788-c6d9-4486-bbc3-25b6a71a0904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.8.2)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.4.0)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.16)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2023.5.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.240)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.14)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.38.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.100.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.10)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.11)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.10->gradio) (2023.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Elasticsearch\n",
        "!pip install elasticsearch\n",
        "\n",
        "# Iniciar Elasticsearch\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# Langchain\n",
        "!pip install langchain\n",
        "\n",
        "# Gradio\n",
        "!pip install gradio\n",
        "\n",
        "# Python\n",
        "import os\n",
        "import gradio as gr\n",
        "from langchain import OpenAI\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "\n",
        "# Tu código...\n",
        "\n",
        "# Detener elasticsearch al final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PpLcECQxoKmM",
        "outputId": "60be13db-d4a7-465b-b267-32d8c116cd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-8b846505dcd4>:33: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-23-8b846505dcd4>:33: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-23-8b846505dcd4>:33: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7873, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can also try \"gpt2-medium\" or \"gpt2-large\" for larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load documents from the file\n",
        "def load_documents(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load the training documents\n",
        "file_path = \"entrenamiento.txt\"\n",
        "docs = load_documents(file_path)\n",
        "\n",
        "def chatbot(input_text):\n",
        "    # Encode the input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate a response using the GPT-2 model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "app = gr.Interface(fn=chatbot,\n",
        "                   inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
        "                   outputs=\"text\",\n",
        "                   title=\"Chatbot\")\n",
        "\n",
        "app.launch(share=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b36bUPbQp5BS"
      },
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "EcmLfe3arA0C",
        "outputId": "8b11e290-051b-4005-b063-af49de297fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-0a37c9ad9ee1>:38: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-25-0a37c9ad9ee1>:38: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-25-0a37c9ad9ee1>:38: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7874, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can also try \"gpt2-medium\" or \"gpt2-large\" for larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load documents from the file\n",
        "def load_documents(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load the training documents\n",
        "file_path = \"entrenamiento.txt\"\n",
        "docs = load_documents(file_path)\n",
        "\n",
        "def chatbot(input_text):\n",
        "    # Encode the input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate a response using the GPT-2 model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids,\n",
        "                                max_length=100,\n",
        "                                num_return_sequences=1,\n",
        "                                pad_token_id=tokenizer.eos_token_id,\n",
        "                                do_sample=True,   # Set to True for response generation\n",
        "                                top_k=50,        # Control the diversity of generated responses\n",
        "                                temperature=0.7) # Control the randomness of generated responses\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "app = gr.Interface(fn=chatbot,\n",
        "                   inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
        "                   outputs=\"text\",\n",
        "                   title=\"Chatbot\")\n",
        "\n",
        "app.launch(share=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDENu9L44Zs1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "t1x-BRBAo-Kd",
        "outputId": "f18e5347-fd87-4758-bbab-03041714156e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-e46ea3e90641>:43: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-26-e46ea3e90641>:43: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-26-e46ea3e90641>:43: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7875, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# Load the pre-trained BART model and tokenizer\n",
        "model_name = \"facebook/bart-large\"  # You can try other BART variants if needed\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Rest of your code...\n",
        "\n",
        "\n",
        "# Load documents from the file\n",
        "def load_documents(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load the training documents from \"entrenamiento.txt\"\n",
        "file_path = \"entrenamiento.txt\"\n",
        "training_data = load_documents(file_path)\n",
        "\n",
        "# Fine-tune the model on the training dataset\n",
        "for example in training_data:\n",
        "    input_text = \"context: \" + example + \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    model.train()\n",
        "    model(input_ids=input_ids)\n",
        "\n",
        "# Chatbot function using the fine-tuned T5 model\n",
        "def chatbot(input_text):\n",
        "    input_text = \"context: \" + input_text + \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True, num_return_sequences=1)\n",
        "\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Create and launch the Gradio interface\n",
        "app = gr.Interface(fn=chatbot,\n",
        "                   inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
        "                   outputs=\"text\",\n",
        "                   title=\"Chatbot\")\n",
        "\n",
        "app.launch(share=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "IBaJK4jQ0Z2P",
        "outputId": "49b1b0d1-e3e4-4f0b-edfe-17c0f63191fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-d2008866b9f0>:37: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-27-d2008866b9f0>:37: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-27-d2008866b9f0>:37: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b0df186e50e543dab0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b0df186e50e543dab0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can try \"gpt2-medium\" or \"gpt2-large\" for larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load documents from the file\n",
        "def load_documents(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load the training documents from \"entrenamiento.txt\"\n",
        "file_path = \"entrenamiento.txt\"\n",
        "training_data = load_documents(file_path)\n",
        "\n",
        "# Combine the training data and some predefined responses for the chatbot\n",
        "chatbot_responses = training_data + [\n",
        "    \"El comedor universitario solo atiende en el almuerzo; no tiene desayuno ni cena.\",\n",
        "    \"Para tener acceso al comedor universitario, es requisito indispensable estar en extrema pobreza y vivir en provincia y distritos pobres.\",\n",
        "    \"Los pasos para obtener tu bachiller son: terminar tu carrera, no deber nada a la Universidad, presentar el certificado de prácticas preprofesionales y tu ficha de matrícula.\"\n",
        "]\n",
        "\n",
        "def chatbot(input_text):\n",
        "    input_text = \"User: \" + input_text + \" \"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True, num_return_sequences=1)\n",
        "\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "app = gr.Interface(fn=chatbot,\n",
        "                   inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
        "                   outputs=\"text\",\n",
        "                   title=\"Chatbot\")\n",
        "\n",
        "app.launch(share=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kojbr23h4bgc"
      },
      "source": [
        "CLAUDE CODIGO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "zt_8zRQT4elz",
        "outputId": "e8282969-85a8-40b9-9ff5-0d63931ac9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7877, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Cargar el modelo GPT-2 entrenado\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Cargar el tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Definir la función para responder\n",
        "def responde(pregunta):\n",
        "\n",
        "  # Codificar la pregunta\n",
        "  inputs = tokenizer(pregunta, return_tensors=\"pt\")\n",
        "\n",
        "  # Generar respuestas con el modelo\n",
        "  outputs = model.generate(inputs[\"input_ids\"],\n",
        "                           max_length=150,\n",
        "                           do_sample=True,\n",
        "                           top_p=0.95,\n",
        "                           top_k=50,\n",
        "                           temperature=0.8)\n",
        "\n",
        "  # Decodificar la respuesta\n",
        "  texto = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  return texto\n",
        "\n",
        "# Interfaz con Gradio\n",
        "interfaz = gr.Interface(fn=responde,\n",
        "                        inputs=\"text\",\n",
        "                        outputs=\"text\",\n",
        "                        title=\"GPT-2 Chatbot\",\n",
        "                        description=\"Hazme una pregunta sobre comedor universitario o trámite de bachiller\")\n",
        "\n",
        "interfaz.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can also try \"gpt2-medium\" or \"gpt2-large\" for larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load documents from the file\n",
        "def load_documents(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load the training documents\n",
        "file_path = \"datos1.txt\"\n",
        "docs = load_documents(file_path)\n",
        "\n",
        "def chatbot(input_text):\n",
        "    # Encode the input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate a response using the GPT-2 model\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids,\n",
        "                                max_length=100,\n",
        "                                num_return_sequences=1,\n",
        "                                pad_token_id=tokenizer.eos_token_id,\n",
        "                                do_sample=True,   # Set to True for response generation\n",
        "                                top_k=50,        # Control the diversity of generated responses\n",
        "                                temperature=0.7) # Control the randomness of generated responses\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "app = gr.Interface(fn=chatbot,\n",
        "                   inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
        "                   outputs=\"text\",\n",
        "                   title=\"Chatbot\")\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "WTqnqtfC0mvV",
        "outputId": "10b7c45b-371c-4aa4-ce3f-a27e9f23faf6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8acd7e8d4b68>:38: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-30-8acd7e8d4b68>:38: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n",
            "<ipython-input-30-8acd7e8d4b68>:38: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Textbox(lines=5, label=\"ingresa una petición\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f2616b53e104a39ddf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f2616b53e104a39ddf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqsX2aav192_",
        "outputId": "cb86ef47-21cc-40ae-91e0-1021591804e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['La Importancia De La Inteligencia Artificial en la Vida Del Ser',\n",
              " 'Humano',\n",
              " 'Para iniciar déjame hacerte una pregunta ¿cuál es tu red social favorita? Sea cual sea, todas utilizan',\n",
              " 'inteligencia artificial. La Inteligencia artificial logra que las máquinas tengan conocimientos de tus',\n",
              " 'hábitos, desde procesos básicos hasta situaciones más avanzadas como el reconocimiento de tu voz,',\n",
              " 'entre otras cosas. Pero ¿qué es la Inteligencia Artificial? ¿por qué es importante para el ser humano?',\n",
              " 'En este artículo, se responderán estas cuestiones.',\n",
              " 'Inteligencia Artificial',\n",
              " 'La Inteligencia artificial es la combinación de algoritmos desarrollados con la finalidad de crear',\n",
              " 'programas y mecanismos que tengan capacidades similares al del ser humano. En un concepto',\n",
              " 'práctico, se puede decir que la IA, es que las máquinas hagan y piensen como seres humanos.',\n",
              " 'John McCarthy en 1956 emitió el término Inteligencia Artificial y lo definió como “la ciencia y el ingenio',\n",
              " 'de hacer máquinas inteligentes, especialmente programas informáticos inteligentes”.',\n",
              " 'La IA posee un gran potencial para resolver problemas difíciles del presente y del futuro, y tiene un',\n",
              " 'impacto mayúsculo en el ser humano.',\n",
              " 'Con la IA las computadoras empiezan a pensar, a reescribir y rediseñar sus propios programas.',\n",
              " 'Como el caso muy comentado del proyecto que en parte ha financiado Facebook. En un laboratorio',\n",
              " 'de investigación sobre inteligencia artificial de la Universidad Tecnológica de Georgia, el proyecto,',\n",
              " 'para crear una inteligencia artificial capaz de aprender y desarrollar nuevas habilidades de',\n",
              " 'negociación, dio un vuelco inesperado, para asombro de la empresa. Los responsables del proyecto',\n",
              " 'tuvieron que apagar el proceso porque la inteligencia artificial había desarrollado su propio lenguaje,',\n",
              " 'casi imposible de descifrar para los investigadores, pero mucho más apto y lógico para la tarea que',\n",
              " 'debía realizar.',\n",
              " 'Como pudimos notar, a pesar de que la IA, creo su propio lenguaje, fue muy apto, para lo que tenía',\n",
              " 'que desempeñar. Con esto no estoy diciendo que tengamos miedo a la IA, sino que veamos la',\n",
              " 'capacidad tan grande que tiene para beneficio de la humanidad.',\n",
              " 'Analicemos algunos rubros donde se utiliza y que ha servido en gran medida para hacernos la vida',\n",
              " 'más fácil. Nos puede dar la facultad de escuchar y ver mejor, así como dotarnos de nuevas',\n",
              " 'capacidades. La IA es sin lugar a duda, una tecnología “disruptiva” que en los próximos años puede',\n",
              " 'cambiar el concepto actual del trabajo, además de que puede mejorar nuestra calidad de vida y la',\n",
              " 'salud de manera significativa.',\n",
              " 'Algunas aplicaciones que usamos diariamente que utilizan IA y seguro has escuchado de ellas o las',\n",
              " 'utilizado.',\n",
              " 'Siri funciona como un asistente personal, ya que utiliza procesamiento de lenguaje natural.',\n",
              " 'Facebook y Google Fotos sugieren el etiquetado y la compilación de fotos con base al',\n",
              " 'reconocimiento de imagen.',\n",
              " 'Amazon ofrece recomendaciones de productos basadas en modelos de canasta de compra.',\n",
              " 'Waze brinda información optimizada de tráfico y navegación en tiempo real.',\n",
              " 'Inteligencia Artificial en la medicina',\n",
              " 'Guillermo Molero Castillo, integrante del laboratorio de Inteligencia Artificial de la Universidad',\n",
              " 'Nacional Autónoma de México (UNAM) explicó que la IA “tiene el potencial de cambiar de manera',\n",
              " 'significativa la atención médica y la salud del paciente, ya que se pueden detectar enfermedades',\n",
              " 'genéticas; monitorear la frecuencia cardíaca, presión arterial, temperatura y niveles de glucosa; así',\n",
              " 'como analizar los factores ambientales. Al obtener todos estos datos, las bases pueden relacionarse',\n",
              " 'con otros datos sociales y utilizarse para crear nuevos modelos inteligencia artificial, con los que',\n",
              " 'podrían predecirse ciertas enfermedades, notificar anticipadamente afecciones mortales, como',\n",
              " 'derrames cerebrales y ataques cardíacos, o advertir sobre reacciones adversas a un medicamento”.',\n",
              " 'Aunque en México, todavía falta mucho para lograr todo esto, en algunos países, ya se realizan',\n",
              " 'procedimientos quirúrgicos más fácilmente con la ayuda de la IA, como el caso de la empresa de',\n",
              " 'tecnología sanitaria Digital Surgery en Reino Unido, que desarrolló con éxito el primer sistema de IA',\n",
              " 'dinámico, diseñado para cirugías. Esta compañía construye los datos para promocionar el futuro de la',\n",
              " 'cirugía, por medio de mapas de ruta de procedimientos quirúrgicos patentados, que tienen como',\n",
              " 'finalidad ayudar al equipo médico a reducir el riesgo y lograr que la cirugía sea más segura.',\n",
              " 'Inteligencia artificial en la educación',\n",
              " 'La IA tiene el poder de transformar trascendentalmente la educación, según lo afirma la UNESCO. De',\n",
              " 'conformidad con la organización, ésta puede simplificar el acceso al aprendizaje, automatizar los',\n",
              " 'procesos de gestión y optimizar los métodos de enseñanza que permiten mejorar el aprendizaje. Así,',\n",
              " 'más personas se beneficiarán de programas educativos, además, de que reducirá las tareas',\n",
              " 'repetitivas de los profesores e impulsará la formación personalizada, mientras da mayor relevancia al',\n",
              " 'aprendizaje colaborativo. La IA puede hacer frente a los desafíos tradicionales de la enseñanza en el',\n",
              " 'marco de las transformaciones.',\n",
              " 'Inteligencia artificial en la vida diaria',\n",
              " 'La IA está en nuestra vida cotidiana más de lo que nos podemos imaginar, por ejemplo, cuando',\n",
              " 'ingresamos al estacionamiento de un centro comercial, la placa o matricula de nuestro auto, es',\n",
              " 'reconocida gracias a la IA. Y si hablamos del teléfono móvil, hay muchas formas de IA, que se utiliza.',\n",
              " 'Por ejemplo, para guiarnos, cuando buscamos alguna dirección, o la mejor ruta, nos orienta para',\n",
              " 'llegar a nuestro destino. También cuando interactuamos con nuestro asistente virtual, además,',\n",
              " 'cuando las plataformas de contenidos nos hacen sugerencias que se adaptan a nuestras',\n",
              " 'preferencias. También cuando nuestro celular reconoce nuestra huella digital o nuestro rostro. En la',\n",
              " 'casa, podemos utilizar la IA, para climatizar, encender o apagar luces o cuando la televisión, el',\n",
              " 'refrigerador o la lavadora, conectadas al internet, hacen diversas funciones, como iniciar el ciclo de',\n",
              " 'lavado, aunque estemos fuera de casa y así podríamos seguir enumerando muchas más actividades',\n",
              " 'cotidianas donde interviene la IA. (Botti, 2019)',\n",
              " 'Existen otras áreas donde la IA está tomando mucha relevancia, como en la agricultura, la ciencia, la',\n",
              " 'aeronáutica, la electrónica, la computación, entre otras.',\n",
              " 'Como pudimos notar, la IA cada día toma mayor trascendencia en la vida del ser humano, sus',\n",
              " 'implicaciones han llevado a considerarla como algo muy útil y necesario, que nos ha servido para',\n",
              " 'mejorar la calidad vida']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}